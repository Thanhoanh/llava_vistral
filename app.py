import gradio as gr
from PIL import Image
from transformers import AutoTokenizer, AutoModelForCausalLM
from models.vision_encoder import CLIPVisionEncoder
from models.projector import ProjectorMLP
from models.image_generator import ImageGenerator
import torch

# Load m√¥ h√¨nh ng√¥n ng·ªØ
llm = AutoModelForCausalLM.from_pretrained(
    "vistral-mm",
    torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32
).eval()
tokenizer = AutoTokenizer.from_pretrained("vistral-mm")

# Load m√¥ h√¨nh th·ªã gi√°c
vision_encoder = CLIPVisionEncoder("openai/clip-vit-base-patch32")
projector = ProjectorMLP(input_dim=512, output_dim=llm.config.hidden_size)

# Load m√¥ h√¨nh sinh ·∫£nh
image_generator = ImageGenerator("configs/diffusion_config.yaml")

def analyze_image_and_question(image, question):
    features = vision_encoder(image)
    if features.dim() == 1:
        features = features.unsqueeze(0)
    image_embed = projector(features)

    # Sinh c√¢u tr·∫£ l·ªùi t·ª´ c√¢u h·ªèi
    prompt = question
    inputs = tokenizer(prompt, return_tensors="pt").to(llm.device)
    with torch.no_grad():
        outputs = llm.generate(**inputs, max_new_tokens=150)
    return tokenizer.decode(outputs[0], skip_special_tokens=True)

def generate_image(prompt):
    image = image_generator.generate(prompt)
    return image

# Giao di·ªán Gradio
with gr.Blocks() as demo:
    gr.Markdown("# üß† Vistral-Multimodal: Tr·ª£ l√Ω Y t·∫ø Ti·∫øng Vi·ªát")

    with gr.Tab("üñºÔ∏è ·∫¢nh + VƒÉn b·∫£n ‚Üí Tr·∫£ l·ªùi"):
        with gr.Row():
            image_input = gr.Image(type="pil", label="·∫¢nh y t·∫ø")
            text_input = gr.Textbox(label="C√¢u h·ªèi v·ªÅ ·∫£nh", placeholder="VD: ·∫¢nh n√†y bi·ªÉu th·ªã ƒëi·ªÅu g√¨?")
        output = gr.Textbox(label="üìã Tr·∫£ l·ªùi t·ª´ m√¥ h√¨nh")
        btn = gr.Button("Ph√¢n t√≠ch")
        btn.click(analyze_image_and_question, inputs=[image_input, text_input], outputs=output)

    with gr.Tab("üìù VƒÉn b·∫£n ‚Üí üñºÔ∏è ·∫¢nh"):
        prompt_input = gr.Textbox(label="Nh·∫≠p m√¥ t·∫£ tri·ªáu ch·ª©ng", placeholder="VD: Ban ƒë·ªè h√¨nh c√°nh b∆∞·ªõm tr√™n m·∫∑t")
        image_output = gr.Image(label="·∫¢nh ƒë∆∞·ª£c sinh")
        btn2 = gr.Button("Sinh ·∫£nh")
        btn2.click(generate_image, inputs=prompt_input, outputs=image_output)

if __name__ == "__main__":
    demo.launch(server_name="0.0.0.0", server_port=7860, share=True)
